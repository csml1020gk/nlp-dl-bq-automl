{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GK-NLP using TransferLearning BERT .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c7e15ca5ee614d90ae6cc2806ce7d4fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f720e7ae9cc74bb5bf9a9117ffd6577f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_38612356fa2b480cb9aea923af234a39",
              "IPY_MODEL_fb5d7fb5ff624e5ab9cafdfd1c38f376"
            ]
          }
        },
        "f720e7ae9cc74bb5bf9a9117ffd6577f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "38612356fa2b480cb9aea923af234a39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_60dceed6ee314e03b9fce2435944b90a",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_16d664d8a679438599261f9ac0441fbf"
          }
        },
        "fb5d7fb5ff624e5ab9cafdfd1c38f376": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_852960c827fd42bd9a667511ee56ac5c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 1.54MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_001c1cc2c0df4dc39535097a074f1546"
          }
        },
        "60dceed6ee314e03b9fce2435944b90a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "16d664d8a679438599261f9ac0441fbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "852960c827fd42bd9a667511ee56ac5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "001c1cc2c0df4dc39535097a074f1546": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8bca02cb2f294623907f88886d5d4017": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8d230f6301654dcf9bf4d8c9fd9ffbc9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e2eaf817d74d428491bbd09c628f70a3",
              "IPY_MODEL_85417109c77146b4b13a3bf7dfc4d004"
            ]
          }
        },
        "8d230f6301654dcf9bf4d8c9fd9ffbc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e2eaf817d74d428491bbd09c628f70a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4a265530297b419090d9e07ddd3f551d",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 442,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 442,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d205590ebba34c4788aec56ff3505a0e"
          }
        },
        "85417109c77146b4b13a3bf7dfc4d004": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_523a3a2e92024259875a9149c5ca1bcf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 442/442 [00:00&lt;00:00, 497B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d1cce53b6622434fb86a2daea64c37fa"
          }
        },
        "4a265530297b419090d9e07ddd3f551d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d205590ebba34c4788aec56ff3505a0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "523a3a2e92024259875a9149c5ca1bcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d1cce53b6622434fb86a2daea64c37fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "109fe10b4b3443c0a1f7c61f368349cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d6fe0d72b01e4ea6b046a7f68b22a723",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_24ada62f848d4215be02d8a4f668737e",
              "IPY_MODEL_40f3c63fd17c45398e9b3e884a5028ec"
            ]
          }
        },
        "d6fe0d72b01e4ea6b046a7f68b22a723": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "24ada62f848d4215be02d8a4f668737e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_82fa5775926f412cbff08b430fa573ef",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 267967963,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 267967963,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_41672c09f650478b9ffb81d0e7731a05"
          }
        },
        "40f3c63fd17c45398e9b3e884a5028ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3db652e4ed094c3bae8664877666e558",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 268M/268M [00:06&lt;00:00, 38.5MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4e6dcca8e118461baa5e962295313e85"
          }
        },
        "82fa5775926f412cbff08b430fa573ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "41672c09f650478b9ffb81d0e7731a05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3db652e4ed094c3bae8664877666e558": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4e6dcca8e118461baa5e962295313e85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izA3-6kffbdT"
      },
      "source": [
        "\n",
        "\n",
        "# Part 1 \n",
        "\n",
        "# We explore two Pretrained models \n",
        "\n",
        "# DistilBERT \n",
        "references used : http://jalammar.github.io/illustrated-bert/\n",
        "dataset: https://nlp.stanford.edu/sentiment/index.html\n",
        "\n",
        "\n",
        "# TensorFlow \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSHtqHmxs9cj"
      },
      "source": [
        "\n",
        "In this notebook, we will use pre-trained deep learning model to process some text. We will then use the output of that model to classify the text. The text is a list of sentences from film reviews. And we will calssify each sentence as either speaking \"positively\" about its subject of \"negatively\".\n",
        "\n",
        "## Models: Sentence Sentiment Classification\n",
        "Our goal is to create a model that takes a sentence (just like the ones in our dataset) and produces either 1 (indicating the sentence carries a positive sentiment) or a 0 (indicating the sentence carries a negative sentiment). We can think of it as looking like this:\n",
        "\n",
        "<img src=\"https://jalammar.github.io/images/distilBERT/sentiment-classifier-1.png\" />\n",
        "\n",
        "Under the hood, the model is actually made up of two models.\n",
        "\n",
        "* DistilBERT processes the sentence and passes along some information it extracted from it on to the next model. DistilBERT is a smaller version of BERT developed and open sourced by the team at HuggingFace. Itâ€™s a lighter and faster version of BERT that roughly matches its performance.\n",
        "* The next model, a basic Logistic Regression model from scikit learn will take in the result of DistilBERTâ€™s processing, and classify the sentence as either positive or negative (1 or 0, respectively).\n",
        "\n",
        "The data we pass between the two models is a vector of size 768. We can think of this of vector as an embedding for the sentence that we can use for classification.\n",
        "\n",
        "\n",
        "\n",
        "## Dataset\n",
        "The dataset we will use in this example is [SST2](https://nlp.stanford.edu/sentiment/index.html), which contains sentences from movie reviews, each labeled as either positive (has the value 1) or negative (has the value 0):\n",
        "\n",
        "\n",
        "<table class=\"features-table\">\n",
        "  <tr>\n",
        "    <th class=\"mdc-text-light-green-600\">\n",
        "    sentence\n",
        "    </th>\n",
        "    <th class=\"mdc-text-purple-600\">\n",
        "    label\n",
        "    </th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td class=\"mdc-bg-light-green-50\" style=\"text-align:left\">\n",
        "      a stirring , funny and finally transporting re imagining of beauty and the beast and 1930s horror films\n",
        "    </td>\n",
        "    <td class=\"mdc-bg-purple-50\">\n",
        "      1\n",
        "    </td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td class=\"mdc-bg-light-green-50\" style=\"text-align:left\">\n",
        "      apparently reassembled from the cutting room floor of any given daytime soap\n",
        "    </td>\n",
        "    <td class=\"mdc-bg-purple-50\">\n",
        "      0\n",
        "    </td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td class=\"mdc-bg-light-green-50\" style=\"text-align:left\">\n",
        "      they presume their audience won't sit still for a sociology lesson\n",
        "    </td>\n",
        "    <td class=\"mdc-bg-purple-50\">\n",
        "      0\n",
        "    </td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td class=\"mdc-bg-light-green-50\" style=\"text-align:left\">\n",
        "      this is a visually stunning rumination on love , memory , history and the war between art and commerce\n",
        "    </td>\n",
        "    <td class=\"mdc-bg-purple-50\">\n",
        "      1\n",
        "    </td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td class=\"mdc-bg-light-green-50\" style=\"text-align:left\">\n",
        "      jonathan parker 's bartleby should have been the be all end all of the modern office anomie films\n",
        "    </td>\n",
        "    <td class=\"mdc-bg-purple-50\">\n",
        "      1\n",
        "    </td>\n",
        "  </tr>\n",
        "</table>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jb7X7C23uSlB"
      },
      "source": [
        "## Installing the transformers library\n",
        "Installing the huggingface transformers library to load our deep learning NLP \n",
        "\n",
        "---\n",
        "\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "To9ENLU90WGl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b376d426-c7bf-4874-bc01-478c7a59ae3b"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/b1/41130a228dd656a1a31ba281598a968320283f48d42782845f6ba567f00b/transformers-4.2.2-py3-none-any.whl (1.8MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.8MB 6.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Collecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.9MB 27.1MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 37.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=f76de7c47649a22b95b39c0fd18d822538a3277be7f43d9f9bcd0e977bda0875\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFu5RkgnPY0B"
      },
      "source": [
        "Import necessary libraries "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvFvBLJV0Dkv"
      },
      "source": [
        "import numpy as np # numpy for linear algebra \n",
        "import pandas as pd # pandas for data manipulaiton\n",
        "from sklearn.model_selection import train_test_split #to split data into train and test sets \n",
        "from sklearn.linear_model import LogisticRegression #algorithm used to classify text vectors \n",
        "from sklearn.model_selection import GridSearchCV # to search for best paramenters \n",
        "from sklearn.model_selection import cross_val_score #evaluate a score by cross validation\n",
        "\n",
        "import torch\n",
        "import transformers as ppb\n",
        "\n",
        "\n",
        "import warnings\n",
        "\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQ-42fh0hjsF"
      },
      "source": [
        "## Importing the dataset\n",
        "We'll use pandas to read the dataset and load it into a dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyoj29J24hPX"
      },
      "source": [
        "df = pd.read_csv('https://github.com/clairett/pytorch-sentiment-classification/raw/master/data/SST2/train.tsv', delimiter='\\t', header=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMVE3waNhuNj"
      },
      "source": [
        "For performance reasons, we'll only use 2,000 sentences from the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Z7YMoyTVUeK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "b48442fd-9d88-4607-fd8a-44f078cf003d"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>a stirring , funny and finally transporting re...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>apparently reassembled from the cutting room f...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>they presume their audience wo n't sit still f...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>this is a visually stunning rumination on love...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>jonathan parker 's bartleby should have been t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   0  1\n",
              "0  a stirring , funny and finally transporting re...  1\n",
              "1  apparently reassembled from the cutting room f...  0\n",
              "2  they presume their audience wo n't sit still f...  0\n",
              "3  this is a visually stunning rumination on love...  1\n",
              "4  jonathan parker 's bartleby should have been t...  1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTM3hOHW4hUY"
      },
      "source": [
        "batch_1 = df[:2000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRc2L89hh1Tf"
      },
      "source": [
        "We can ask pandas how many sentences are labeled as \"positive\" (value 1) and how many are labeled \"negative\" (having the value 0)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGvcfcCP5xpZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02961790-18ca-4e72-af0c-0c25ada8ec60"
      },
      "source": [
        "batch_1[1].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    1041\n",
              "0     959\n",
              "Name: 1, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qq0dCZvnVima"
      },
      "source": [
        "Pretty balanced "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_sPaYldVhA0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "995647c8-de27-4f97-969a-02bdfae7168b"
      },
      "source": [
        "batch_1[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       a stirring , funny and finally transporting re...\n",
              "1       apparently reassembled from the cutting room f...\n",
              "2       they presume their audience wo n't sit still f...\n",
              "3       this is a visually stunning rumination on love...\n",
              "4       jonathan parker 's bartleby should have been t...\n",
              "                              ...                        \n",
              "1995    too bland and fustily tasteful to be truly pru...\n",
              "1996                           it does n't work as either\n",
              "1997    this one aims for the toilet and scores a dire...\n",
              "1998    in the name of an allegedly inspiring and easi...\n",
              "1999    the movie is undone by a filmmaking methodolog...\n",
              "Name: 0, Length: 2000, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_MO08_KiAOb"
      },
      "source": [
        "## Loading the Pre-trained BERT model DISTILBERT - it is a smaller version of BERT \n",
        "Let's now load a pre-trained BERT model. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bp1qkL7eV48s"
      },
      "source": [
        "We use distilbert-base-uncased\n",
        "Why uncased ? Because we might lose valuabe information if we ignore the case "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1InADgf5xm2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164,
          "referenced_widgets": [
            "c7e15ca5ee614d90ae6cc2806ce7d4fd",
            "f720e7ae9cc74bb5bf9a9117ffd6577f",
            "38612356fa2b480cb9aea923af234a39",
            "fb5d7fb5ff624e5ab9cafdfd1c38f376",
            "60dceed6ee314e03b9fce2435944b90a",
            "16d664d8a679438599261f9ac0441fbf",
            "852960c827fd42bd9a667511ee56ac5c",
            "001c1cc2c0df4dc39535097a074f1546",
            "8bca02cb2f294623907f88886d5d4017",
            "8d230f6301654dcf9bf4d8c9fd9ffbc9",
            "e2eaf817d74d428491bbd09c628f70a3",
            "85417109c77146b4b13a3bf7dfc4d004",
            "4a265530297b419090d9e07ddd3f551d",
            "d205590ebba34c4788aec56ff3505a0e",
            "523a3a2e92024259875a9149c5ca1bcf",
            "d1cce53b6622434fb86a2daea64c37fa",
            "109fe10b4b3443c0a1f7c61f368349cd",
            "d6fe0d72b01e4ea6b046a7f68b22a723",
            "24ada62f848d4215be02d8a4f668737e",
            "40f3c63fd17c45398e9b3e884a5028ec",
            "82fa5775926f412cbff08b430fa573ef",
            "41672c09f650478b9ffb81d0e7731a05",
            "3db652e4ed094c3bae8664877666e558",
            "4e6dcca8e118461baa5e962295313e85"
          ]
        },
        "outputId": "21a593ba-ccc6-42f8-a633-c77c8922ecf1"
      },
      "source": [
        "# For DistilBERT:\n",
        "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
        "\n",
        "## Want BERT instead of distilBERT? Uncomment the following line:\n",
        "#model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
        "\n",
        "# Load pretrained model/tokenizer\n",
        "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
        "model = model_class.from_pretrained(pretrained_weights)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c7e15ca5ee614d90ae6cc2806ce7d4fd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8bca02cb2f294623907f88886d5d4017",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=442.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "109fe10b4b3443c0a1f7c61f368349cd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=267967963.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZDBMn3wiSX6"
      },
      "source": [
        "Right now, the variable `model` holds a pretrained distilBERT model -- a version of BERT that is smaller, but much faster and requiring a lot less memory.\n",
        "\n",
        "# Model #1: Preparing the Dataset\n",
        "Before we can hand our sentences to BERT, we need to so some minimal processing to put them in the format it requires.\n",
        "\n",
        "### Tokenization\n",
        "Our first step is to tokenize the sentences -- break them up into word and subwords in the format BERT is comfortable with.\n",
        "\n",
        "Take sentences - apply lambda to the sentence : encode , add special tokens for eacn sentence in the df coumn \n",
        "\n",
        "Turns every sentence into a list of ids "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dg82ndBA5xlN"
      },
      "source": [
        "tokenized = batch_1[0].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuYKRpKKY4pa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d14a6428-73c1-4114-ae0e-361cbd89195e"
      },
      "source": [
        "# list of lists \n",
        "tokenized"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       [101, 1037, 18385, 1010, 6057, 1998, 2633, 182...\n",
              "1       [101, 4593, 2128, 27241, 23931, 2013, 1996, 62...\n",
              "2       [101, 2027, 3653, 23545, 2037, 4378, 24185, 10...\n",
              "3       [101, 2023, 2003, 1037, 17453, 14726, 19379, 1...\n",
              "4       [101, 5655, 6262, 1005, 1055, 12075, 2571, 376...\n",
              "                              ...                        \n",
              "1995    [101, 2205, 20857, 1998, 11865, 16643, 2135, 5...\n",
              "1996    [101, 2009, 2515, 1050, 1005, 1056, 2147, 2004...\n",
              "1997    [101, 2023, 2028, 8704, 2005, 1996, 11848, 199...\n",
              "1998    [101, 1999, 1996, 2171, 1997, 2019, 9382, 1898...\n",
              "1999    [101, 1996, 3185, 2003, 25757, 2011, 1037, 244...\n",
              "Name: 0, Length: 2000, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tG-g7_lGPHHK",
        "outputId": "0b4057eb-95ff-4a5e-e5a2-d213b2213f0a"
      },
      "source": [
        "tokenized.values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([list([101, 1037, 18385, 1010, 6057, 1998, 2633, 18276, 2128, 16603, 1997, 5053, 1998, 1996, 6841, 1998, 5687, 5469, 3152, 102]),\n",
              "       list([101, 4593, 2128, 27241, 23931, 2013, 1996, 6276, 2282, 2723, 1997, 2151, 2445, 12217, 7815, 102]),\n",
              "       list([101, 2027, 3653, 23545, 2037, 4378, 24185, 1050, 1005, 1056, 4133, 2145, 2005, 1037, 11507, 10800, 1010, 2174, 14036, 2135, 3591, 1010, 2061, 2027, 19817, 4140, 2041, 1996, 7511, 2671, 4349, 3787, 1997, 11829, 7168, 9219, 1998, 28971, 2308, 1999, 8301, 8737, 2100, 4253, 102]),\n",
              "       ...,\n",
              "       list([101, 2023, 2028, 8704, 2005, 1996, 11848, 1998, 7644, 1037, 3622, 2718, 102]),\n",
              "       list([101, 1999, 1996, 2171, 1997, 2019, 9382, 18988, 1998, 4089, 3006, 3085, 17312, 1010, 1996, 3750, 1005, 1055, 2252, 4332, 1037, 6397, 3239, 2000, 1996, 2200, 2381, 2009, 9811, 2015, 2000, 6570, 102]),\n",
              "       list([101, 1996, 3185, 2003, 25757, 2011, 1037, 24466, 16134, 2008, 1005, 1055, 2074, 6388, 2438, 2000, 7344, 3686, 1996, 7731, 4378, 2096, 13060, 18856, 17322, 2094, 2000, 15015, 10271, 4641, 102])],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHwjUwYgi-uL"
      },
      "source": [
        "<img src=\"https://jalammar.github.io/images/distilBERT/bert-distilbert-tokenization-2-token-ids.png\" />\n",
        "\n",
        "### Padding\n",
        "After tokenization, `tokenized` is a list of sentences -- each sentences is represented as a list of tokens. We want BERT to process our examples all at once (as one batch). It's just faster that way. For that reason, we need to pad all lists to the same size, so we can represent the input as one 2-d array, rather than a list of lists (of different lengths)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URn-DWJt5xhP"
      },
      "source": [
        "max_len = 0\n",
        "#iterate through the list of lists \n",
        "for i in tokenized.values:\n",
        "#what is the maximum length of a review out of the 2000 reviews \n",
        "#if the length of a review is greater than a certain size , pad it to a \n",
        "    if len(i) > max_len:\n",
        "        max_len = len(i)\n",
        "#the maximum length of a review is 59 \n",
        "#max_len\n",
        "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zpBDl57M5f5",
        "outputId": "971ac66b-ded9-42e1-9992-b1221813e6a0"
      },
      "source": [
        "print(\"Padded array\", padded.ndim, \"dimensions\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Padded array 2 dimensions\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LegUSIRLNI8Z",
        "outputId": "9973c09a-2771-4533-c32e-cc699b6c2424"
      },
      "source": [
        "print(\"Shape of Padded array\", padded.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of Padded array (2000, 59)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IzoxTFKCNFkI",
        "outputId": "435b0cfa-2537-4e86-8414-1c820e54f93e"
      },
      "source": [
        "print(\"Size of Padded array\", padded.size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of Padded array 118000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwmovNewNaQP",
        "outputId": "813f20bf-3023-43ee-f023-e92dbfdd9e2b"
      },
      "source": [
        "print(\"Datatype of Padded array\", padded.dtype)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Datatype of Padded array int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWdrowshNjqI",
        "outputId": "68277166-4dd4-42cd-ce8e-e87e2a42c531"
      },
      "source": [
        "print(\"Size of Padded array elements (in bytes)\", padded.itemsize)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of Padded array elements (in bytes) 8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHUHQONhN6Ip",
        "outputId": "bd2c7b66-e006-4957-ea54-5f0597bb9521"
      },
      "source": [
        "#size times itemsize\n",
        "print(\"Total Size of the Padded array (in bytes)\", padded.nbytes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Size of the Padded array (in bytes) 944000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mdjg306wjjmL"
      },
      "source": [
        "Our dataset is now in the `padded` variable, we can view its dimensions below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdi7uXo95xeq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93f35200-7848-4d84-9420-23e8b9bab045"
      },
      "source": [
        "np.array(padded).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 59)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntTAbT07RJRq",
        "outputId": "be47e0a3-f2b5-471c-a9ec-9e80cd2ba2ee"
      },
      "source": [
        "padded[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  101,  1037, 18385,  1010,  6057,  1998,  2633, 18276,  2128,\n",
              "       16603,  1997,  5053,  1998,  1996,  6841,  1998,  5687,  5469,\n",
              "        3152,   102,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DEVB_p2RRf5",
        "outputId": "4465a47e-ef21-4a0b-8084-108683ae9444"
      },
      "source": [
        "padded[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  101,  4593,  2128, 27241, 23931,  2013,  1996,  6276,  2282,\n",
              "        2723,  1997,  2151,  2445, 12217,  7815,   102,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0I5sDENRskQ"
      },
      "source": [
        "The purpose of padding is to make the lists the same size , but the data is not in a form BERT expects "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDZBsYSDjzDV"
      },
      "source": [
        "### Masking\n",
        "If we directly send `padded` to BERT, that would slightly confuse it. We need to create another variable to tell it to ignore (mask) the padding we've added when it's processing its input. That's what attention_mask is:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4K_iGRNa_Ozc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59dab1b4-4520-4943-c454-f1b373ba4756"
      },
      "source": [
        "#return elements from padded array where \n",
        "#attention_mask = np.where(padded != 0, 1, 0)\n",
        "attention_mask = np.where(padded != 0,1,0)\n",
        "attention_mask"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXwAKmM4TJ1w",
        "outputId": "30a47afd-2b5b-4cae-dcec-ef6e633d9603"
      },
      "source": [
        "attention_mask.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 59)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jK-CQB9-kN99"
      },
      "source": [
        "## Model #1: And Now, Deep Learning!\n",
        "Now that we have our model and inputs ready, let's run our model!\n",
        "\n",
        "<img src=\"https://jalammar.github.io/images/distilBERT/bert-distilbert-tutorial-sentence-embedding.png\" />\n",
        "\n",
        "The `model()` function runs our sentences through BERT. The results of the processing will be returned into `last_hidden_states`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPr5aa97Tssa"
      },
      "source": [
        "PyTorch \n",
        "\n",
        "is a replacement for Numpy to use the power of  GPUs and other accelerators \n",
        "\n",
        "Library used to implement neural networks \n",
        "\n",
        "Tensors and multiple syntaxes \n",
        "\n",
        "Tensors are used to encode the inputs and outputs of a model as well as the model's parameters \n",
        "\n",
        "Libraries imported with \" import torch \"\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUIIEs2-W_Rg",
        "outputId": "fee85067-d0ca-4542-cef1-2009a2a8bb30"
      },
      "source": [
        "input_ids = torch.tensor(padded) \n",
        "input_ids"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  101,  1037, 18385,  ...,     0,     0,     0],\n",
              "        [  101,  4593,  2128,  ...,     0,     0,     0],\n",
              "        [  101,  2027,  3653,  ...,     0,     0,     0],\n",
              "        ...,\n",
              "        [  101,  2023,  2028,  ...,     0,     0,     0],\n",
              "        [  101,  1999,  1996,  ...,     0,     0,     0],\n",
              "        [  101,  1996,  3185,  ...,     0,     0,     0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEthZNrGXKQZ",
        "outputId": "13d9b28a-7881-4be5-8f0c-e92f3e0bd234"
      },
      "source": [
        "attention_mask = torch.tensor(attention_mask)\n",
        "attention_mask"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39UVjAV56PJz"
      },
      "source": [
        " #We use no_grad() Context Manager because we are sure there will not be any backward propagation happening here \n",
        " #To reduce memory consumption \n",
        " #Even if the inputs have requires_grad = True, requires+grad = False will be used \n",
        " with torch.no_grad():\n",
        "    last_hidden_states = model(input_ids, attention_mask=attention_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoCep_WVuB3v"
      },
      "source": [
        "Let's slice only the part of the output that we need. That is the output corresponding the first token of each sentence. The way BERT does sentence classification, is that it adds a token called `[CLS]` (for classification) at the beginning of every sentence. The output corresponding to that token can be thought of as an embedding for the entire sentence.\n",
        "\n",
        "<img src=\"https://jalammar.github.io/images/distilBERT/bert-output-tensor-selection.png\" />\n",
        "\n",
        "We'll save those in the `features` variable, as they'll serve as the features to our logistic regression model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUUOEPVNadPS",
        "outputId": "95a7620f-3b72-409d-c985-2cf38d39aff3"
      },
      "source": [
        "#datatype of last_hidden_states , the model output - tensor data \n",
        "last_hidden_states\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BaseModelOutput([('last_hidden_state',\n",
              "                  tensor([[[-0.2159, -0.1403,  0.0083,  ..., -0.1369,  0.5867,  0.2011],\n",
              "                           [-0.2471,  0.2468,  0.1008,  ..., -0.1631,  0.9349, -0.0715],\n",
              "                           [ 0.0558,  0.3573,  0.4140,  ..., -0.2430,  0.1770, -0.5080],\n",
              "                           ...,\n",
              "                           [-0.0165,  0.1179,  0.3512,  ..., -0.2401,  0.2722, -0.1750],\n",
              "                           [ 0.0961,  0.0667,  0.3147,  ..., -0.3277,  0.3556, -0.2135],\n",
              "                           [ 0.0454,  0.0519,  0.3168,  ..., -0.2880,  0.1844, -0.1042]],\n",
              "                  \n",
              "                          [[-0.1726, -0.1448,  0.0022,  ..., -0.1744,  0.2139,  0.3720],\n",
              "                           [ 0.0022,  0.1684,  0.1269,  ..., -0.1888, -0.0195, -0.0283],\n",
              "                           [ 0.0257, -0.2458,  0.0717,  ..., -0.4339,  0.1622,  0.0133],\n",
              "                           ...,\n",
              "                           [ 0.0505, -0.0493,  0.0463,  ..., -0.0448, -0.0540,  0.3136],\n",
              "                           [-0.2128, -0.1907, -0.0215,  ...,  0.0139, -0.2433, -0.0202],\n",
              "                           [-0.1310, -0.1693,  0.1019,  ..., -0.0859, -0.1770, -0.0872]],\n",
              "                  \n",
              "                          [[-0.0506,  0.0720, -0.0296,  ..., -0.0715,  0.7185,  0.2623],\n",
              "                           [ 0.0536,  0.3136, -0.0598,  ...,  0.2676,  0.8668, -0.3380],\n",
              "                           [ 0.3792,  0.2792,  0.0237,  ...,  0.0343,  0.4272,  0.1680],\n",
              "                           ...,\n",
              "                           [ 0.2314,  0.2427,  0.1030,  ..., -0.0840,  0.2322,  0.0613],\n",
              "                           [ 0.0741,  0.0465,  0.1083,  ...,  0.0530,  0.1971,  0.0233],\n",
              "                           [ 0.1042,  0.3139,  0.0768,  ..., -0.0301,  0.1052, -0.0780]],\n",
              "                  \n",
              "                          ...,\n",
              "                  \n",
              "                          [[-0.2783, -0.2480,  0.1359,  ..., -0.1904,  0.1310,  0.3498],\n",
              "                           [-0.4406, -0.5159,  0.1700,  ..., -0.3430,  0.3747,  0.0846],\n",
              "                           [-0.4604, -0.3928,  0.0390,  ..., -0.3068, -0.1666,  0.2803],\n",
              "                           ...,\n",
              "                           [-0.2033, -0.2213,  0.2879,  ..., -0.2334, -0.1342,  0.1061],\n",
              "                           [-0.0998, -0.2407,  0.1394,  ..., -0.1828, -0.0762,  0.2031],\n",
              "                           [-0.0663, -0.1063,  0.1606,  ..., -0.2004, -0.2571,  0.1438]],\n",
              "                  \n",
              "                          [[-0.0367,  0.1064, -0.0111,  ..., -0.1121,  0.4162,  0.5034],\n",
              "                           [-0.1869,  0.3485, -0.8375,  ..., -0.1169,  0.3985,  0.3065],\n",
              "                           [-0.3108,  0.2174, -0.1678,  ..., -0.1267,  0.3512, -0.0812],\n",
              "                           ...,\n",
              "                           [ 0.0874,  0.0203,  0.0381,  ...,  0.1545,  0.0125,  0.1109],\n",
              "                           [ 0.2528, -0.0149,  0.0847,  ...,  0.0441,  0.1973,  0.2889],\n",
              "                           [ 0.2378, -0.0568,  0.2862,  ...,  0.0842,  0.1540,  0.1655]],\n",
              "                  \n",
              "                          [[ 0.1240,  0.0143,  0.0104,  ..., -0.1161,  0.5346,  0.2750],\n",
              "                           [ 0.1294, -0.2348, -0.0882,  ...,  0.0997,  1.1743, -0.3309],\n",
              "                           [ 0.5874, -0.1074, -0.0561,  ..., -0.0401,  0.3627, -0.4122],\n",
              "                           ...,\n",
              "                           [ 0.4066, -0.1452,  0.0651,  ...,  0.0879,  0.3980, -0.1256],\n",
              "                           [ 0.4385, -0.1488,  0.1139,  ..., -0.0744,  0.3416, -0.3278],\n",
              "                           [ 0.5451, -0.0851,  0.1311,  ..., -0.0017,  0.3413, -0.3513]]]))])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9t60At16PVs"
      },
      "source": [
        "#convert back to numpy array for use with sklearn algorithms\n",
        "\n",
        "features = last_hidden_states[0][:,0,:].numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bzDKC7JbaTD",
        "outputId": "5c2585a3-b5b5-46d3-f126-dd60c1fd2dc3"
      },
      "source": [
        "features"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.21593434, -0.14028926,  0.00831123, ..., -0.13694869,\n",
              "         0.5867001 ,  0.20112717],\n",
              "       [-0.17262726, -0.1447617 ,  0.00223425, ..., -0.17442562,\n",
              "         0.21386456,  0.37197497],\n",
              "       [-0.05063343,  0.07203954, -0.02959665, ..., -0.07148951,\n",
              "         0.7185235 ,  0.26225498],\n",
              "       ...,\n",
              "       [-0.27829763, -0.24803594,  0.13585813, ..., -0.1903916 ,\n",
              "         0.13099582,  0.34978363],\n",
              "       [-0.03667719,  0.10638559, -0.01111007, ..., -0.11206657,\n",
              "         0.41619483,  0.50338006],\n",
              "       [ 0.12402609,  0.01425178,  0.01038435, ..., -0.11606541,\n",
              "         0.5345915 ,  0.27495354]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VZVU66Gurr-"
      },
      "source": [
        "Until now, we were working on the review column of our batch of 2000 reviews.The labels indicating which sentence is positive and negative now go into the `labels` variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JD3fX2yh6PTx"
      },
      "source": [
        "labels = batch_1[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaoEvM2evRx1"
      },
      "source": [
        "## sklearn model : Train/Test Split\n",
        "Let's now split our datset into a training set and testing set (even though we're using 2,000 sentences from the SST2 training set)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddAqbkoU6PP9"
      },
      "source": [
        "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, random_state = 42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTsMsfcYgHe7"
      },
      "source": [
        "We converted the input reviews into a format suitable for BERT\n",
        "\n",
        "Ran our model \n",
        "\n",
        "Then converted the features back into a numpy array\n",
        "\n",
        "Did our train/ test split \n",
        "\n",
        "We are going to use sklearn Logistic Regression\n",
        "\n",
        "We have our sentence embeddings from DISTIL-BERT and labels \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9bhSJpcv1Bl"
      },
      "source": [
        "<img src=\"https://jalammar.github.io/images/distilBERT/bert-distilbert-train-test-split-sentence-embedding.png\" />\n",
        "\n",
        "### Grid Search for Parameters\n",
        "We can dive into Logistic regression directly with the Scikit Learn default parameters, but sometimes it's worth searching for the best value of the C parameter, which determines regularization strength."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyEwr7yYD3Ci",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87c6ed53-dcef-4de1-9471-ef16169f1522"
      },
      "source": [
        "parameters = {'C': np.linspace(0.0001, 100, 20)}\n",
        "grid_search = GridSearchCV(LogisticRegression(), parameters)\n",
        "grid_search.fit(train_features, train_labels)\n",
        "\n",
        "print('Best parameters: ', grid_search.best_params_)\n",
        "print('Best scores: ', grid_search.best_score_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best parameters:  {'C': 5.263252631578947}\n",
            "Best scores:  0.8193333333333334\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCT9u8vAwnID"
      },
      "source": [
        "We now train the LogisticRegression model using the value of C found through GridSearchCV "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gG-EVWx4CzBc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82ca56ef-1837-4a05-eb5f-c8301959bb91"
      },
      "source": [
        "lr_clf = LogisticRegression(C=5.2)\n",
        "lr_clf.fit(train_features, train_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=5.2, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rUMKuVgwzkY"
      },
      "source": [
        "<img src=\"https://jalammar.github.io/images/distilBERT/bert-training-logistic-regression.png\" />\n",
        "\n",
        "## Evaluating Model 1\n",
        "So how well does our model do in classifying sentences? One way is to check the accuracy against the testing dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCoyxRJ7ECTA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c235345-7d5e-4063-ddfd-7a4a9f273298"
      },
      "source": [
        "lr_clf.score(test_features, test_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.838"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75oyhr3VxHoE"
      },
      "source": [
        "How good is this score? What can we compare it against? Let's first look at a dummy classifier\n",
        "\n",
        "This classifier is useful as a simple baseline to compare with other (real) classifiers\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnwgmqNG7i5l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b3eb77c-3c73-4668-a9e5-f24cabb9c6ca"
      },
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "clf = DummyClassifier()\n",
        "#Evaluate a score by cross-validation using cross_val_score from sklearn,model.selection \n",
        "scores = cross_val_score(clf, train_features, train_labels)\n",
        "#Returns the mean accuracy on the given test data and labels\n",
        "print(\"Dummy classifier score: %0.3f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dummy classifier score: 0.495 (+/- 0.07)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Lg4LOpoxSOR"
      },
      "source": [
        "So our model clearly does better than a dummy classifier. But how does it compare against the best models?\n",
        "\n",
        "## Proper SST2 scores\n",
        "For reference, the [highest accuracy score](http://nlpprogress.com/english/sentiment_analysis.html) for this dataset is currently **96.8**.\n",
        "\n",
        "DistilBERT can be trained to improve its score on this task â€“ a process called **fine-tuning** which updates BERTâ€™s weights to make it achieve a better performance in this sentence classification task (which we can call the downstream task). \n",
        "\n",
        "The fine-tuned DistilBERT turns out to achieve an accuracy score of **90.7**. The full size BERT model achieves **94.9**.\n",
        "\n",
        "\n",
        "The next step would be to head over to the documentation and try [fine-tuning](https://huggingface.co/transformers/examples.html#glue). \n",
        "\n",
        "We can also go back and switch from distilBERT to BERT and see how that works."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2VkZuVEKjxU"
      },
      "source": [
        "# Model #2 Using TensorFlow \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1aFXaL34O9-j"
      },
      "source": [
        "Install BERT for TensorFlow \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0EJ3VVbOv7k"
      },
      "source": [
        "pip install -q tensorflow-hub\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHLlfT-XXOKD"
      },
      "source": [
        "Install libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWQ_5hKfdNCb",
        "outputId": "e2808c18-39f5-4b25-9ed9-04908b010165"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "print(\"Version: \", tf.__version__)\n",
        "print(\"Eager mode: \", tf.executing_eagerly())\n",
        "print(\"Hub version: \", hub.__version__)\n",
        "print(\"GPU is\", \"available\" if tf.config.experimental.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Version:  2.4.1\n",
            "Eager mode:  True\n",
            "Hub version:  0.11.0\n",
            "GPU is NOT AVAILABLE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XT2BdzW0PHX0"
      },
      "source": [
        "Version of TensorFlow \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-d1L1LNdWR2",
        "outputId": "8d109a0b-5426-4d75-e9af-7fe348ef92f3"
      },
      "source": [
        "# Split the training set into 60% and 40%, so we'll end up with 15,000 examples\n",
        "# for training, 10,000 examples for validation and 25,000 examples for testing.\n",
        "train_data, validation_data, test_data = tfds.load(\n",
        "    name=\"imdb_reviews\", \n",
        "    split=('train[:60%]', 'train[60%:]', 'test'),\n",
        "    as_supervised=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split ('train[:60%]', 'train[60%:]', 'test'), from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_k36arD4eMki",
        "outputId": "625ba1f8-b083-40ec-dccf-e151ca67a6b7"
      },
      "source": [
        "train_examples_batch, train_labels_batch = next(iter(train_data.batch(10)))\n",
        "train_examples_batch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=string, numpy=\n",
              "array([b\"This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\",\n",
              "       b'I have been known to fall asleep during films, but this is usually due to a combination of things including, really tired, being warm and comfortable on the sette and having just eaten a lot. However on this occasion I fell asleep because the film was rubbish. The plot development was constant. Constantly slow and boring. Things seemed to happen, but with no explanation of what was causing them or why. I admit, I may have missed part of the film, but i watched the majority of it and everything just seemed to happen of its own accord without any real concern for anything else. I cant recommend this film at all.',\n",
              "       b'Mann photographs the Alberta Rocky Mountains in a superb fashion, and Jimmy Stewart and Walter Brennan give enjoyable performances as they always seem to do. <br /><br />But come on Hollywood - a Mountie telling the people of Dawson City, Yukon to elect themselves a marshal (yes a marshal!) and to enforce the law themselves, then gunfighters battling it out on the streets for control of the town? <br /><br />Nothing even remotely resembling that happened on the Canadian side of the border during the Klondike gold rush. Mr. Mann and company appear to have mistaken Dawson City for Deadwood, the Canadian North for the American Wild West.<br /><br />Canadian viewers be prepared for a Reefer Madness type of enjoyable howl with this ludicrous plot, or, to shake your head in disgust.',\n",
              "       b'This is the kind of film for a snowy Sunday afternoon when the rest of the world can go ahead with its own business as you descend into a big arm-chair and mellow for a couple of hours. Wonderful performances from Cher and Nicolas Cage (as always) gently row the plot along. There are no rapids to cross, no dangerous waters, just a warm and witty paddle through New York life at its best. A family film in every sense and one that deserves the praise it received.',\n",
              "       b'As others have mentioned, all the women that go nude in this film are mostly absolutely gorgeous. The plot very ably shows the hypocrisy of the female libido. When men are around they want to be pursued, but when no \"men\" are around, they become the pursuers of a 14 year old boy. And the boy becomes a man really fast (we should all be so lucky at this age!). He then gets up the courage to pursue his true love.',\n",
              "       b\"This is a film which should be seen by anybody interested in, effected by, or suffering from an eating disorder. It is an amazingly accurate and sensitive portrayal of bulimia in a teenage girl, its causes and its symptoms. The girl is played by one of the most brilliant young actresses working in cinema today, Alison Lohman, who was later so spectacular in 'Where the Truth Lies'. I would recommend that this film be shown in all schools, as you will never see a better on this subject. Alison Lohman is absolutely outstanding, and one marvels at her ability to convey the anguish of a girl suffering from this compulsive disorder. If barometers tell us the air pressure, Alison Lohman tells us the emotional pressure with the same degree of accuracy. Her emotional range is so precise, each scene could be measured microscopically for its gradations of trauma, on a scale of rising hysteria and desperation which reaches unbearable intensity. Mare Winningham is the perfect choice to play her mother, and does so with immense sympathy and a range of emotions just as finely tuned as Lohman's. Together, they make a pair of sensitive emotional oscillators vibrating in resonance with one another. This film is really an astonishing achievement, and director Katt Shea should be proud of it. The only reason for not seeing it is if you are not interested in people. But even if you like nature films best, this is after all animal behaviour at the sharp edge. Bulimia is an extreme version of how a tormented soul can destroy her own body in a frenzy of despair. And if we don't sympathise with people suffering from the depths of despair, then we are dead inside.\",\n",
              "       b'Okay, you have:<br /><br />Penelope Keith as Miss Herringbone-Tweed, B.B.E. (Backbone of England.) She\\'s killed off in the first scene - that\\'s right, folks; this show has no backbone!<br /><br />Peter O\\'Toole as Ol\\' Colonel Cricket from The First War and now the emblazered Lord of the Manor.<br /><br />Joanna Lumley as the ensweatered Lady of the Manor, 20 years younger than the colonel and 20 years past her own prime but still glamourous (Brit spelling, not mine) enough to have a toy-boy on the side. It\\'s alright, they have Col. Cricket\\'s full knowledge and consent (they guy even comes \\'round for Christmas!) Still, she\\'s considerate of the colonel enough to have said toy-boy her own age (what a gal!)<br /><br />David McCallum as said toy-boy, equally as pointlessly glamourous as his squeeze. Pilcher couldn\\'t come up with any cover for him within the story, so she gave him a hush-hush job at the Circus.<br /><br />and finally:<br /><br />Susan Hampshire as Miss Polonia Teacups, Venerable Headmistress of the Venerable Girls\\' Boarding-School, serving tea in her office with a dash of deep, poignant advice for life in the outside world just before graduation. Her best bit of advice: \"I\\'ve only been to Nancherrow (the local Stately Home of England) once. I thought it was very beautiful but, somehow, not part of the real world.\" Well, we can\\'t say they didn\\'t warn us.<br /><br />Ah, Susan - time was, your character would have been running the whole show. They don\\'t write \\'em like that any more. Our loss, not yours.<br /><br />So - with a cast and setting like this, you have the re-makings of \"Brideshead Revisited,\" right?<br /><br />Wrong! They took these 1-dimensional supporting roles because they paid so well. After all, acting is one of the oldest temp-jobs there is (YOU name another!)<br /><br />First warning sign: lots and lots of backlighting. They get around it by shooting outdoors - \"hey, it\\'s just the sunlight!\"<br /><br />Second warning sign: Leading Lady cries a lot. When not crying, her eyes are moist. That\\'s the law of romance novels: Leading Lady is \"dewy-eyed.\"<br /><br />Henceforth, Leading Lady shall be known as L.L.<br /><br />Third warning sign: L.L. actually has stars in her eyes when she\\'s in love. Still, I\\'ll give Emily Mortimer an award just for having to act with that spotlight in her eyes (I wonder . did they use contacts?)<br /><br />And lastly, fourth warning sign: no on-screen female character is \"Mrs.\" She\\'s either \"Miss\" or \"Lady.\"<br /><br />When all was said and done, I still couldn\\'t tell you who was pursuing whom and why. I couldn\\'t even tell you what was said and done.<br /><br />To sum up: they all live through World War II without anything happening to them at all.<br /><br />OK, at the end, L.L. finds she\\'s lost her parents to the Japanese prison camps and baby sis comes home catatonic. Meanwhile (there\\'s always a \"meanwhile,\") some young guy L.L. had a crush on (when, I don\\'t know) comes home from some wartime tough spot and is found living on the street by Lady of the Manor (must be some street if SHE\\'s going to find him there.) Both war casualties are whisked away to recover at Nancherrow (SOMEBODY has to be \"whisked away\" SOMEWHERE in these romance stories!)<br /><br />Great drama.',\n",
              "       b'The film is based on a genuine 1950s novel.<br /><br />Journalist Colin McInnes wrote a set of three \"London novels\": \"Absolute Beginners\", \"City of Spades\" and \"Mr Love and Justice\". I have read all three. The first two are excellent. The last, perhaps an experiment that did not come off. But McInnes\\'s work is highly acclaimed; and rightly so. This musical is the novelist\\'s ultimate nightmare - to see the fruits of one\\'s mind being turned into a glitzy, badly-acted, soporific one-dimensional apology of a film that says it captures the spirit of 1950s London, and does nothing of the sort.<br /><br />Thank goodness Colin McInnes wasn\\'t alive to witness it.',\n",
              "       b'I really love the sexy action and sci-fi films of the sixties and its because of the actress\\'s that appeared in them. They found the sexiest women to be in these films and it didn\\'t matter if they could act (Remember \"Candy\"?). The reason I was disappointed by this film was because it wasn\\'t nostalgic enough. The story here has a European sci-fi film called \"Dragonfly\" being made and the director is fired. So the producers decide to let a young aspiring filmmaker (Jeremy Davies) to complete the picture. They\\'re is one real beautiful woman in the film who plays Dragonfly but she\\'s barely in it. Film is written and directed by Roman Coppola who uses some of his fathers exploits from his early days and puts it into the script. I wish the film could have been an homage to those early films. They could have lots of cameos by actors who appeared in them. There is one actor in this film who was popular from the sixties and its John Phillip Law (Barbarella). Gerard Depardieu, Giancarlo Giannini and Dean Stockwell appear as well. I guess I\\'m going to have to continue waiting for a director to make a good homage to the films of the sixties. If any are reading this, \"Make it as sexy as you can\"! I\\'ll be waiting!',\n",
              "       b'Sure, this one isn\\'t really a blockbuster, nor does it target such a position. \"Dieter\" is the first name of a quite popular German musician, who is either loved or hated for his kind of acting and thats exactly what this movie is about. It is based on the autobiography \"Dieter Bohlen\" wrote a few years ago but isn\\'t meant to be accurate on that. The movie is filled with some sexual offensive content (at least for American standard) which is either amusing (not for the other \"actors\" of course) or dumb - it depends on your individual kind of humor or on you being a \"Bohlen\"-Fan or not. Technically speaking there isn\\'t much to criticize. Speaking of me I find this movie to be an OK-movie.'],\n",
              "      dtype=object)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caRTgFUoeRYF",
        "outputId": "0578edbd-a9c1-48d1-a0a3-0d9c552b1933"
      },
      "source": [
        "train_labels_batch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=int64, numpy=array([0, 0, 0, 1, 1, 1, 0, 0, 0, 0])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fV20ezIeWcH"
      },
      "source": [
        "## Build the CNN model \n",
        "\n",
        "The neural network is created by stacking layersâ€”this requires three main architectural decisions:\n",
        "\n",
        "How to represent the text?\n",
        "\n",
        "How many layers to use in the model?\n",
        "\n",
        "How many hidden units to use for each layer?\n",
        "\n",
        "\n",
        "One way to represent the text is to convert sentences into embeddings vectors\n",
        "\n",
        "We can use a pre-trained text embedding as the first layer, which will have three advantages:\n",
        "\n",
        "we don't have to worry about text preprocessing\n",
        "\n",
        "we can benefit from transfer learning\n",
        "\n",
        "the embedding has a fixed size, so it's simpler to process\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1GQ3XFffevE"
      },
      "source": [
        "Let's first create a Keras layer that uses a TensorFlow Hub model to embed the sentences, and try it out on a couple of input examples.\n",
        "\n",
        "Note that no matter the length of the input text, the output shape of the embeddings is: (num_examples, embedding_dimension)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdXJdeayfXGZ",
        "outputId": "9bfc78fa-8a6e-422e-8c28-faa629f53931"
      },
      "source": [
        "embedding = \"https://tfhub.dev/google/nnlm-en-dim50/2\"\n",
        "hub_layer = hub.KerasLayer(embedding, input_shape=[], \n",
        "                           dtype=tf.string, trainable=True)\n",
        "hub_layer(train_examples_batch[:3])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Using /tmp/tfhub_modules to cache modules.\n",
            "INFO:absl:Downloading TF-Hub Module 'https://tfhub.dev/google/nnlm-en-dim50/2'.\n",
            "INFO:absl:Downloaded https://tfhub.dev/google/nnlm-en-dim50/2, Total size: 191.83MB\n",
            "INFO:absl:Downloaded TF-Hub Module 'https://tfhub.dev/google/nnlm-en-dim50/2'.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 50), dtype=float32, numpy=\n",
              "array([[ 0.5423195 , -0.0119017 ,  0.06337538,  0.06862972, -0.16776837,\n",
              "        -0.10581174,  0.16865303, -0.04998824, -0.31148055,  0.07910346,\n",
              "         0.15442263,  0.01488662,  0.03930153,  0.19772711, -0.12215476,\n",
              "        -0.04120981, -0.2704109 , -0.21922152,  0.26517662, -0.80739075,\n",
              "         0.25833532, -0.3100421 ,  0.28683215,  0.1943387 , -0.29036492,\n",
              "         0.03862849, -0.7844411 , -0.0479324 ,  0.4110299 , -0.36388892,\n",
              "        -0.58034706,  0.30269456,  0.3630897 , -0.15227164, -0.44391504,\n",
              "         0.19462997,  0.19528408,  0.05666234,  0.2890704 , -0.28468323,\n",
              "        -0.00531206,  0.0571938 , -0.3201318 , -0.04418665, -0.08550783,\n",
              "        -0.55847436, -0.23336391, -0.20782952, -0.03543064, -0.17533456],\n",
              "       [ 0.56338924, -0.12339553, -0.10862679,  0.7753425 , -0.07667089,\n",
              "        -0.15752277,  0.01872335, -0.08169781, -0.3521876 ,  0.4637341 ,\n",
              "        -0.08492756,  0.07166859, -0.00670817,  0.12686075, -0.19326553,\n",
              "        -0.52626437, -0.3295823 ,  0.14394785,  0.09043556, -0.5417555 ,\n",
              "         0.02468163, -0.15456742,  0.68333143,  0.09068331, -0.45327246,\n",
              "         0.23180096, -0.8615696 ,  0.34480393,  0.12838456, -0.58759046,\n",
              "        -0.4071231 ,  0.23061076,  0.48426893, -0.27128142, -0.5380916 ,\n",
              "         0.47016326,  0.22572741, -0.00830663,  0.2846242 , -0.304985  ,\n",
              "         0.04400365,  0.25025874,  0.14867121,  0.40717036, -0.15422426,\n",
              "        -0.06878027, -0.40825695, -0.3149215 ,  0.09283665, -0.20183425],\n",
              "       [ 0.7456154 ,  0.21256861,  0.14400336,  0.5233862 ,  0.11032254,\n",
              "         0.00902788, -0.3667802 , -0.08938274, -0.24165542,  0.33384594,\n",
              "        -0.11194605, -0.01460047, -0.0071645 ,  0.19562712,  0.00685216,\n",
              "        -0.24886718, -0.42796347,  0.18620004, -0.05241098, -0.66462487,\n",
              "         0.13449019, -0.22205497,  0.08633006,  0.43685386,  0.2972681 ,\n",
              "         0.36140734, -0.7196889 ,  0.05291241, -0.14316116, -0.1573394 ,\n",
              "        -0.15056328, -0.05988009, -0.08178931, -0.15569411, -0.09303783,\n",
              "        -0.18971172,  0.07620788, -0.02541647, -0.27134508, -0.3392682 ,\n",
              "        -0.10296468, -0.27275252, -0.34078008,  0.20083304, -0.26644835,\n",
              "         0.00655449, -0.05141488, -0.04261917, -0.45413622,  0.20023568]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCp-SUTsfnyM"
      },
      "source": [
        "Let's now build the full model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gXW_P8Ffl9N",
        "outputId": "ba9a2814-d437-43c7-ab39-9fa0c705ac43"
      },
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(hub_layer)\n",
        "model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(1))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "keras_layer (KerasLayer)     (None, 50)                48190600  \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 16)                816       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 48,191,433\n",
            "Trainable params: 48,191,433\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53xkIz2ff9fW"
      },
      "source": [
        "The layers are stacked sequentially to build the classifier:\n",
        "\n",
        "The first layer is a TensorFlow Hub layer.\n",
        "\n",
        "This layer uses a pre-trained Saved Model to map a sentence into its embedding vector.\n",
        "\n",
        "The pre-trained text embedding model that we are using (google/nnlm-en-dim50/2) splits the sentence into tokens, embeds each token and then combines the embedding.\n",
        "\n",
        "The resulting dimensions are: (num_examples, embedding_dimension). For this NNLM model, the embedding_dimension is 50.\n",
        "\n",
        "This fixed-length output vector is piped through a fully-connected (Dense) layer with 16 hidden units.\n",
        "\n",
        "The last layer is densely connected with a single output node.\n",
        "Let's compile the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-KgEAgbgH7a"
      },
      "source": [
        "Define loss functions to use \n",
        "\n",
        "A model needs a loss function and an optimizer for training. Since this is a binary classification problem and the model outputs logits (a single-unit layer with a linear activation), we'll use the binary_crossentropy loss function.\n",
        "\n",
        "This isn't the only choice for a loss function, you could, for instance, choose mean_squared_error. But, generally, binary_crossentropy is better for dealing with probabilitiesâ€”it measures the \"distance\" between probability distributions, or in our case, between the ground-truth distribution and the predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5dPp_FtgUyt"
      },
      "source": [
        "Train the model \n",
        "\n",
        "Train the model for 10 epochs in mini-batches of 512 samples. \n",
        "\n",
        "This is 10 iterations over all samples in the x_train and y_train tensors. \n",
        "\n",
        "While training, monitor the model's loss and accuracy on the 10,000 samples from the validation set:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLyp0pE0gX70",
        "outputId": "405d0680-8be4-46a6-989d-eb0dc365aa86"
      },
      "source": [
        "history = model.fit(train_data.shuffle(10000).batch(512),\n",
        "                    epochs=10,\n",
        "                    validation_data=validation_data.batch(512),\n",
        "                    verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "30/30 [==============================] - 7s 205ms/step - loss: 0.6969 - accuracy: 0.5297 - val_loss: 0.5996 - val_accuracy: 0.6732\n",
            "Epoch 2/10\n",
            "30/30 [==============================] - 6s 195ms/step - loss: 0.5594 - accuracy: 0.6898 - val_loss: 0.5006 - val_accuracy: 0.7380\n",
            "Epoch 3/10\n",
            "30/30 [==============================] - 6s 196ms/step - loss: 0.4418 - accuracy: 0.7938 - val_loss: 0.4131 - val_accuracy: 0.8233\n",
            "Epoch 4/10\n",
            "30/30 [==============================] - 7s 201ms/step - loss: 0.3335 - accuracy: 0.8776 - val_loss: 0.3553 - val_accuracy: 0.8431\n",
            "Epoch 5/10\n",
            "30/30 [==============================] - 7s 200ms/step - loss: 0.2432 - accuracy: 0.9121 - val_loss: 0.3233 - val_accuracy: 0.8622\n",
            "Epoch 6/10\n",
            "30/30 [==============================] - 6s 199ms/step - loss: 0.1863 - accuracy: 0.9425 - val_loss: 0.3081 - val_accuracy: 0.8687\n",
            "Epoch 7/10\n",
            "30/30 [==============================] - 6s 198ms/step - loss: 0.1390 - accuracy: 0.9600 - val_loss: 0.3027 - val_accuracy: 0.8685\n",
            "Epoch 8/10\n",
            "30/30 [==============================] - 6s 199ms/step - loss: 0.1023 - accuracy: 0.9746 - val_loss: 0.3037 - val_accuracy: 0.8694\n",
            "Epoch 9/10\n",
            "30/30 [==============================] - 6s 195ms/step - loss: 0.0762 - accuracy: 0.9838 - val_loss: 0.3089 - val_accuracy: 0.8725\n",
            "Epoch 10/10\n",
            "30/30 [==============================] - 7s 201ms/step - loss: 0.0583 - accuracy: 0.9898 - val_loss: 0.3179 - val_accuracy: 0.8699\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAfgt5eUhxDo"
      },
      "source": [
        "Evaluate the model\n",
        "\n",
        "And let's see how the model performs.\n",
        "\n",
        "Two values will be returned. \n",
        "\n",
        "Loss (a number which represents our error, lower values are better), and accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5hlUUgAhzxP",
        "outputId": "517be31c-7f9a-45c1-dba2-c07fe1888afa"
      },
      "source": [
        "results = model.evaluate(test_data.batch(512), verbose=2)\n",
        "\n",
        "for name, value in zip(model.metrics_names, results):\n",
        "  print(\"%s: %.3f\" % (name, value))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "49/49 - 2s - loss: 0.4869 - accuracy: 0.8495\n",
            "loss: 0.487\n",
            "accuracy: 0.850\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eany0aarh5U5"
      },
      "source": [
        "# We have looked at two transfer learning approaches to classify text reviews using pre trained models provided by BERT HuggingFace and TensorFlow\n",
        "\n",
        "\n"
      ]
    }
  ]
}